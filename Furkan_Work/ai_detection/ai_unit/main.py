import json
import torch
import logging
from kafka_manager import KafkaManager
from image_processor import ImageProcessor
from utils.redis_config import get_redis_client
from utils.logger import setup_logger
from config import Config
#from TRTModelService import TRTModelService
from ai_unit.model_service import ModelService
from collections import Counter


def main():

    # Logger kurulumu
    logger = setup_logger()
    
    try:
        # BaÄŸÄ±mlÄ±lÄ±klarÄ±n kurulumu
        kafka_manager = KafkaManager()
        
        image_processor = ImageProcessor()
        model_service = ModelService()
        #model_service = TRTModelService("models/model.engine")
        redis_client = get_redis_client()
        
        # Kafka baÄŸlantÄ±larÄ±
        consumer = kafka_manager.get_consumer()
        producer = kafka_manager.get_producer()
        
        logger.info("ğŸš€ AI Unit service started successfully")
        
        # Ana iÅŸlem dÃ¶ngÃ¼sÃ¼
        for msg in consumer:
            try:
                process_message(msg, image_processor, model_service, redis_client, producer)
            except Exception as e:
                logger.error(f"Message processing failed: {e}")
                if model_service.device.type == 'cuda':
                    torch.cuda.empty_cache()

    
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Service stopped by user")
    except Exception as e:
        logger.error(f"âŒ Fatal error: {e}")
    finally:
        if 'producer' in locals():
            try:
                producer.flush()
                logger.info("ğŸ“¤ Final producer flush done.")
            except Exception as e:
                logger.warning(f"Flush failed during shutdown: {e}")
            producer.close()
            logger.info("ğŸ”’ Kafka producer closed.")
        if 'consumer' in locals():
            consumer.close()
            logger.info("ğŸ”’ Kafka consumer closed.")
        logger.info("ğŸ”Œ Resources released")

def process_message(msg, image_processor, model_service, redis_client, producer):
    """Tek bir mesajÄ± iÅŸler"""
    logger = setup_logger()
    
    if not msg.value:
        logger.warning("Empty message received")
        return

    frame_id = msg.value.get("frame_id")
    frame_index = msg.value.get("frame_index")
    src_video_id = msg.value.get("src_video_id")
    
    if not all([frame_id, frame_index, src_video_id]):
        logger.error("Invalid message format")
        return

    logger.info(f"Processing frame: {frame_id}")
    
    # Redis'ten veri Ã§ek
    redis_key = f"frame:{frame_id}"
    redis_data = redis_client.get(redis_key)
    if not redis_data:
        logger.warning(f"Frame not found in Redis: {redis_key}")
        return

    # GÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle
    frame_data = json.loads(redis_data)
    frame = image_processor.decode_image(frame_data["filtered_data"])
    if frame is None:
        return

    # Tahmin yap
    predictions = model_service.predict(frame)

    if predictions:
        result = {
            "frame_id": frame_id,
            "frame_index": frame_index,
            "src_video_id": src_video_id,
            "is_detected": True,
            "detections": predictions  
        }

        # Kafka'ya gÃ¶nder
        producer.send(Config.OUTPUT_TOPIC, result)

        producer.flush()


        logger.info(f"âœ… Processed frame {frame_id} with {len(predictions)} detections â€” frame index: {frame_index}")
        for i, pred in enumerate(predictions):
            logger.info(
                f"ğŸ” Detection {i+1} â€” Box: {pred['box']}, "
                f"Confidence: {pred['confidence']:.2f}, "
                f"Type: {pred['weapon_type']}"
            )
    else:
        logger.debug(f"ğŸŸ¡ No detections in frame {frame_id} â€” frame index: {frame_index}")

if __name__ == "__main__":
    main()